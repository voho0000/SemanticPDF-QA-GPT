{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load the .env file located in the project directory\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Change this to the local path where your PDF file is located.\n",
    "local_pdf_path = \"GPT4_MED_sample_paper.pdf\"\n",
    "\n",
    "reader = PdfReader(local_pdf_path)\n",
    "\n",
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"。\", \"！\", \"？\", \"\\n\", \" \"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This paper presents a comparative evaluation of GPT-4, GPT-3.5, and Flan-PaLM 540B on medical competency examinations and benchmark datasets, exploring zero-shot performance as a baseline. The authors discuss the implications of LLM progress, particularly with respect to the potential disruption of social contracts, such as those between professional classes and citizens and governments. The paper also mentions the potential risks and advantages of LLMs, and suggests ways to use them appropriately.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Explain the paper\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5-shot is a few-shot prompt following the template described in Figure 2.1, where 5 examples are randomly selected from the remainder of the dataset.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Ｗhat is 5-shot in this paper\"\n",
    "docs = docsearch_recur.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
